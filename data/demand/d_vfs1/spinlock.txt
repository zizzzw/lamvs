do_raw_spin_trylock() <inline int do_raw_spin_trylock (raw_spinlock_t *lock) at linux/spinlock.h:175>:
    arch_spin_trylock()
spin_is_contended() <__always_inline int spin_is_contended (spinlock_t *lock) at linux/spinlock.h:406>:
    raw_spin_is_contended()
spin_is_locked() <__always_inline int spin_is_locked (spinlock_t *lock) at linux/spinlock.h:401>:
    raw_spin_is_locked()
spin_lock() <__always_inline void spin_lock (spinlock_t *lock) at linux/spinlock.h:308>:
    raw_spin_lock()
spin_lock_bh() <__always_inline void spin_lock_bh (spinlock_t *lock) at linux/spinlock.h:313>:
    raw_spin_lock_bh()
spin_lock_irq() <__always_inline void spin_lock_irq (spinlock_t *lock) at linux/spinlock.h:333>:
    raw_spin_lock_irq()
spin_trylock() <__always_inline int spin_trylock (spinlock_t *lock) at linux/spinlock.h:318>:
    raw_spin_trylock()
spin_trylock_bh() <__always_inline int spin_trylock_bh (spinlock_t *lock) at linux/spinlock.h:368>:
    raw_spin_trylock_bh()
spin_trylock_irq() <__always_inline int spin_trylock_irq (spinlock_t *lock) at linux/spinlock.h:373>:
    raw_spin_trylock_irq()
spin_unlock() <__always_inline void spin_unlock (spinlock_t *lock) at linux/spinlock.h:348>:
    raw_spin_unlock()
spin_unlock_bh() <__always_inline void spin_unlock_bh (spinlock_t *lock) at linux/spinlock.h:353>:
    raw_spin_unlock_bh()
spin_unlock_irq() <__always_inline void spin_unlock_irq (spinlock_t *lock) at linux/spinlock.h:358>:
    raw_spin_unlock_irq()
spin_unlock_irqrestore() <__always_inline void spin_unlock_irqrestore (spinlock_t *lock, unsigned long flags) at linux/spinlock.h:363>:
    raw_spin_unlock_irqrestore()
spinlock_check() <__always_inline raw_spinlock_t *spinlock_check (spinlock_t *lock) at linux/spinlock.h:297>
